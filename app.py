"""app.py
------------------------------
è¯¥æ–‡ä»¶ä½¿ç”¨ FastAPI æ„å»ºå® ç‰©é£Ÿå“å®‰å…¨ AI é—®ç­”åç«¯æœåŠ¡ã€‚
"""

# å¼•å…¥æ ‡å‡†åº“ä¸ç¬¬ä¸‰æ–¹åº“
# - os: è¯»å–ç³»ç»Ÿç¯å¢ƒå˜é‡
# - logging: ç»Ÿä¸€æ—¥å¿—è¾“å‡ºï¼Œæ–¹ä¾¿è°ƒè¯•
# - typing.Optional, typing.Any: ç±»å‹æ³¨è§£
# - fastapi: åˆ›å»º Web æœåŠ¡
# - fastapi.middleware.cors: å¤„ç†è·¨åŸŸè¯·æ±‚
# - fastapi.responses: æµå¼å“åº”æ”¯æŒ
# - pydantic: å®šä¹‰è¯·æ±‚ä½“æ•°æ®æ¨¡å‹
# - zai: å®˜æ–¹æ™ºè°± AI Python SDKï¼Œå°è£…æ¨¡å‹è°ƒç”¨
# - dotenv: ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
import os
import json
import logging
import time
from typing import Optional, Any, Generator

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from dotenv import load_dotenv
from zai import ZhipuAiClient


# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿ ZHIPU_API_KEY åœ¨è¿è¡Œå‰å·²æ­£ç¡®é…ç½®ã€‚
load_dotenv()


# é…ç½®æ—¥å¿—æ ¼å¼ä¸ç­‰çº§ï¼Œä½¿æ§åˆ¶å°å¯ä»¥è¾“å‡ºè¯¦ç»†çš„è¯·æ±‚/å“åº”ä¿¡æ¯ã€‚
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger(__name__)


# åˆå§‹åŒ– FastAPI åº”ç”¨å®ä¾‹ã€‚
app = FastAPI(
    title="å® ç‰©é£Ÿå“å®‰å…¨ AI é—®ç­”åç«¯",
    description="æä¾› POST /ask æ¥å£ï¼Œé€šè¿‡æ™ºè°± AI glm-4 å›ç­”å® ç‰©é£Ÿå“ä¸å¥åº·é—®é¢˜ã€‚",
    version="1.0.0"
)


# é…ç½® CORS ä¸­é—´ä»¶ï¼Œå…è®¸å‰ç«¯åœ¨æœ¬åœ°æˆ–å…¶ä»–åŸŸåä¸‹ç›´æ¥è®¿é—®ã€‚
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å¯æ ¹æ®éœ€è¦é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# å®šä¹‰è¯·æ±‚ä½“æ•°æ®æ¨¡å‹
class PetProfile(BaseModel):
    name: Optional[str] = None
    type: Optional[str] = None
    breed: Optional[str] = None
    allergies: Optional[list[str]] = None

class AskRequest(BaseModel):
    question: str
    pet_profile: Optional[PetProfile] = None  # å¯é€‰çš„å® ç‰©æ¡£æ¡ˆä¿¡æ¯


# æ™ºè°± AI é…ç½®å¸¸é‡ã€‚

def build_system_prompt(pet_profile: Optional[PetProfile] = None) -> str:
    """æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼Œæ ¹æ®å® ç‰©æ¡£æ¡ˆä¿¡æ¯åŠ¨æ€ç”Ÿæˆã€‚
    
    Args:
        pet_profile: å® ç‰©æ¡£æ¡ˆä¿¡æ¯
        
    Returns:
        ç³»ç»Ÿæç¤ºè¯å­—ç¬¦ä¸²
    """
    # ä¼˜åŒ–ï¼šç®€åŒ–æç¤ºè¯ï¼Œå‡å°‘tokenæ•°ï¼ŒåŠ å¿«å“åº”
    base_prompt = "ä½ æ˜¯å® ç‰©è¥å…»ä¸“å®¶ã€‚ç®€è¦å›ç­”ã€‚\né‡è¦ï¼šåªè¾“å‡ºæœ€ç»ˆç­”æ¡ˆï¼Œä¸è¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ã€æ¨ç†è¿‡ç¨‹æˆ–ä»»ä½•æ ‡ç­¾ï¼ˆå¦‚<thinking>ã€<reasoning>ç­‰ï¼‰ã€‚"
    
    # å¦‚æœæœ‰å® ç‰©æ¡£æ¡ˆï¼Œæ·»åŠ è¿‡æ•åŸæ£€æŸ¥æŒ‡ä»¤
    if pet_profile and pet_profile.allergies and len(pet_profile.allergies) > 0:
        pet_name = pet_profile.name or "è¯¥å® ç‰©"
        allergies_str = "ã€".join(pet_profile.allergies)
        base_prompt += f"\nè¿‡æ•åŸï¼š{pet_name}å¯¹{allergies_str}è¿‡æ•ã€‚å¦‚é£Ÿç‰©å«è¿‡æ•åŸï¼Œæ ‡è®°ã€é«˜å±é¢„è­¦ã€‘ï¼Œç¦æ­¢å–‚é£Ÿã€‚"
    
    base_prompt += "\næ ¼å¼ï¼š\nã€é£é™©ç­‰çº§ã€‘ï¼š[ç­‰çº§]\nã€é£é™©ç‚¹ã€‘ï¼š[é£é™©]\nã€å–‚å…»å»ºè®®ã€‘ï¼š[å»ºè®®]"
    
    return base_prompt


ZHIPU_MODEL_NAME: str = "GLM-4-Flash-250414"

# app.py - åœ¨ ZHIPU_MODEL_NAME å¸¸é‡ä¸‹æ–¹åŠ å…¥
# ---------------------------------------------------------------------------
# RAG çŸ¥è¯†åº“
# ---------------------------------------------------------------------------
PET_KNOWLEDGE = {
    "å·§å…‹åŠ›": "ã€é«˜å±é¢„è­¦ã€‘å«å¯å¯ç¢±ï¼Œå¯¹å® ç‰©æœ‰æ¯’ï¼Œå‰‚é‡å¤§æœ‰ç”Ÿå‘½å±é™©ã€‚",  
    "è‘¡è„": "ã€é«˜å±é¢„è­¦ã€‘å¯èƒ½å¯¼è‡´è‚¾è¡°ç«­ï¼Œå°‘é‡ä¹Ÿå±é™©ã€‚å»ºè®®ç«‹å³å°±åŒ»ã€‚", 
    "æ´‹è‘±": "ã€é«˜å±é¢„è­¦ã€‘ç ´åçº¢ç»†èƒï¼Œå¼•èµ·è´«è¡€ï¼Œå‰‚é‡å¤§æœ‰ç”Ÿå‘½å±é™©ã€‚",  
    "æœ¨ç³–é†‡": "ã€é«˜å±é¢„è­¦ã€‘å¯¼è‡´èƒ°å²›ç´ å¤§é‡åˆ†æ³Œï¼Œå¼•èµ·ä½è¡€ç³–ã€è‚è¡°ç«­ï¼Œå¯¹å® ç‰©æåº¦å±é™©ã€‚",
    "ç‰›æ²¹æœ": "ã€ä¸­å±é¢„è­¦ã€‘å«æ¯’æ€§ç‰©è´¨persinï¼Œè™½ç„¶ç‹—çŒ«ååº”è¾ƒå°ï¼Œä½†ä¸å»ºè®®é£Ÿç”¨ã€‚",
    "ç”Ÿé¸¡è›‹": "ã€ä¸­å±é¢„è­¦ã€‘å¯èƒ½å«æœ‰æ²™é—¨æ°èŒï¼Œåº”ç…®ç†Ÿï¼Œé•¿æœŸé£Ÿç”¨ç”Ÿè›‹ç™½ä¼šå½±å“ç”Ÿç‰©ç´ å¸æ”¶ã€‚",  
    "å’–å•¡": "ã€é«˜å±é¢„è­¦ã€‘å«å’–å•¡å› ï¼Œå¯èƒ½å¼•èµ·ä¸­æ¯’ã€‚",
    "èŒ¶": "ã€é«˜å±é¢„è­¦ã€‘å«å’–å•¡å› ã€‚",
    "è¥¿ç“œ": "ã€ä½é£é™©ã€‘å°‘é‡æœè‚‰å®‰å…¨ï¼Œä½†ç§å­å’Œç“œçš®ä¸å®œé£Ÿç”¨ï¼Œç³–å°¿ç—…å® ç‰©éœ€è°¨æ…ã€‚",
    "è‹¹æœ": "ã€ä½é£é™©ã€‘æœè‚‰å®‰å…¨ï¼Œä½†æœæ ¸å«æœ‰æ°°åŒ–ç‰©ï¼Œå¿…é¡»å»é™¤ã€‚",
}


def get_rag_info(question: str) -> str:
    """RAG çŸ¥è¯†æ£€ç´¢ï¼šé€šè¿‡å…³é”®è¯åŒ¹é…ï¼Œä»æœ¬åœ°çŸ¥è¯†åº“ä¸­æ£€ç´¢å®‰å…¨ä¿¡æ¯ã€‚"""
    retrieved_facts = []
    lower_question = question.lower()

    # ä¼˜åŒ–ï¼šä½¿ç”¨æ›´é«˜æ•ˆçš„åŒ¹é…æ–¹å¼ï¼ŒåªåŒ¹é…ç¬¬ä¸€ä¸ªåŒ¹é…é¡¹ï¼ˆå¤§å¤šæ•°æƒ…å†µä¸‹åªéœ€è¦ä¸€ä¸ªï¼‰
    for item, fact in PET_KNOWLEDGE.items():
        if item in lower_question:
            retrieved_facts.append(f"ã€{item}ã€‘{fact}")
            break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…å°±è¿”å›ï¼Œå‡å°‘å¤„ç†æ—¶é—´

    if retrieved_facts:
       # è¿›ä¸€æ­¥ç®€åŒ–æ ¼å¼ï¼Œå‡å°‘tokenæ•°
       return "\nå‚è€ƒï¼š" + retrieved_facts[0]
    else:
        return ""
# ---------------------------------------------------------------------------

import re

def filter_thinking_content(content: str) -> str:
    """è¿‡æ»¤æ€è€ƒè¿‡ç¨‹å†…å®¹ï¼Œç§»é™¤æ€è€ƒè¿‡ç¨‹ç›¸å…³çš„æ ‡ç­¾å’Œæ–‡æœ¬ã€‚
    
    Args:
        content: åŸå§‹å†…å®¹
        
    Returns:
        è¿‡æ»¤åçš„å†…å®¹
    """
    if not content:
        return content
    
    # ç§»é™¤æ€è€ƒè¿‡ç¨‹æ ‡ç­¾ï¼ˆæˆå¯¹æ ‡ç­¾ï¼Œå¦‚<thinking>...</thinking>ï¼‰
    content = re.sub(r'<[^>]*(?:thinking|reasoning|redacted)[^>]*>.*?</[^>]*(?:thinking|reasoning|redacted)[^>]*>', '', content, flags=re.DOTALL | re.IGNORECASE)
    # ç§»é™¤è‡ªé—­åˆæ ‡ç­¾ï¼ˆå¦‚<thinking/>ï¼‰
    content = re.sub(r'<[^>]*(?:thinking|reasoning|redacted)[^>]*/?>', '', content, flags=re.IGNORECASE)
    
    return content

def format_ai_response(text: str) -> str:
    """æ ¼å¼åŒ–AIå›ç­”ï¼Œç¡®ä¿ã€é£é™©ç­‰çº§ã€‘ã€ã€é£é™©ç‚¹ã€‘ã€ã€å–‚å…»å»ºè®®ã€‘ç‹¬ç«‹æˆè¡Œã€‚
    
    Args:
        text: åŸå§‹AIå›ç­”æ–‡æœ¬
        
    Returns:
        æ ¼å¼åŒ–åçš„æ–‡æœ¬
    """
    if not text:
        return text
    
    # ç§»é™¤æ–‡æœ¬é¦–å°¾ç©ºç™½
    text = text.strip()
    
    # è¿‡æ»¤æ€è€ƒè¿‡ç¨‹ï¼šç§»é™¤æ‰€æœ‰æ€è€ƒè¿‡ç¨‹ç›¸å…³çš„æ ‡ç­¾å’Œå†…å®¹
    # åŒ¹é…å„ç§å¯èƒ½çš„æ€è€ƒè¿‡ç¨‹æ ‡ç­¾ï¼ŒåŒ…æ‹¬<thinking>ã€<reasoning>ã€<think>ç­‰
    text = re.sub(r'<[^>]*(?:thinking|reasoning|redacted)[^>]*>.*?</[^>]*(?:thinking|reasoning|redacted)[^>]*>', '', text, flags=re.DOTALL | re.IGNORECASE)
    # åŒ¹é…è‡ªé—­åˆæ ‡ç­¾
    text = re.sub(r'<[^>]*(?:thinking|reasoning|redacted)[^>]*/?>', '', text, flags=re.IGNORECASE)
    # ç§»é™¤å¯èƒ½æ®‹ç•™çš„æ€è€ƒè¿‡ç¨‹å†…å®¹ï¼ˆå¦‚æœæ ‡ç­¾è¢«ç§»é™¤ä½†å†…å®¹è¿˜åœ¨ï¼‰
    text = re.sub(r'æ€è€ƒè¿‡ç¨‹[ï¼š:].*?(?=ã€|$)', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'æ¨ç†è¿‡ç¨‹[ï¼š:].*?(?=ã€|$)', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # ç¬¬ä¸€æ­¥ï¼šç»Ÿä¸€å†’å·æ ¼å¼ï¼ˆè‹±æ–‡å†’å·æ”¹ä¸ºä¸­æ–‡å†’å·ï¼‰
    text = re.sub(r'ã€é£é™©ç­‰çº§ã€‘:\s*', 'ã€é£é™©ç­‰çº§ã€‘ï¼š', text)
    text = re.sub(r'ã€é£é™©ç‚¹ã€‘:\s*', 'ã€é£é™©ç‚¹ã€‘ï¼š', text)
    text = re.sub(r'ã€å–‚å…»å»ºè®®ã€‘:\s*', 'ã€å–‚å…»å»ºè®®ã€‘ï¼š', text)
    
    # ç¬¬äºŒæ­¥ï¼šæœ€å…³é”® - å¼ºåˆ¶åœ¨æ ‡é¢˜ä¹‹é—´æ’å…¥æ¢è¡Œï¼ˆæ›´å…¨é¢çš„åŒ¹é…ï¼‰
    # ä½¿ç”¨æ›´å®½æ³›çš„æ¨¡å¼ï¼ŒåŒ¹é…ä»»æ„å­—ç¬¦ç›´åˆ°ä¸‹ä¸€ä¸ªæ ‡é¢˜
    
    # å¤„ç†ã€é£é™©ç­‰çº§ã€‘å’Œã€é£é™©ç‚¹ã€‘ä¹‹é—´çš„æ¢è¡Œ
    # åŒ¹é…ï¼šã€é£é™©ç­‰çº§ã€‘åé¢ä»»æ„å†…å®¹ç›´åˆ°ã€é£é™©ç‚¹ã€‘
    text = re.sub(r'ã€é£é™©ç­‰çº§ã€‘[:ï¼š]?([^ã€]*?)ã€é£é™©ç‚¹ã€‘', r'ã€é£é™©ç­‰çº§ã€‘ï¼š\1\n\nã€é£é™©ç‚¹ã€‘', text, flags=re.DOTALL)
    
    # å¤„ç†ã€é£é™©ç‚¹ã€‘å’Œã€å–‚å…»å»ºè®®ã€‘ä¹‹é—´çš„æ¢è¡Œ
    text = re.sub(r'ã€é£é™©ç‚¹ã€‘[:ï¼š]?([^ã€]*?)ã€å–‚å…»å»ºè®®ã€‘', r'ã€é£é™©ç‚¹ã€‘ï¼š\1\n\nã€å–‚å…»å»ºè®®ã€‘', text, flags=re.DOTALL)
    
    # ç¬¬å››æ­¥ï¼šç»Ÿä¸€æ ‡é¢˜åçš„å†’å·æ ¼å¼ï¼ˆç¡®ä¿éƒ½æœ‰ä¸­æ–‡å†’å·ï¼‰
    text = re.sub(r'ã€é£é™©ç­‰çº§ã€‘\s*[:ï¼š]\s*', 'ã€é£é™©ç­‰çº§ã€‘ï¼š', text)
    text = re.sub(r'ã€é£é™©ç‚¹ã€‘\s*[:ï¼š]\s*', 'ã€é£é™©ç‚¹ã€‘ï¼š', text)
    text = re.sub(r'ã€å–‚å…»å»ºè®®ã€‘\s*[:ï¼š]\s*', 'ã€å–‚å…»å»ºè®®ã€‘ï¼š', text)
    
    # ç¬¬äº”æ­¥ï¼šé‡æ–°ç»„ç»‡æ–‡æœ¬ï¼Œç¡®ä¿æ¯ä¸ªéƒ¨åˆ†ï¼ˆæ ‡é¢˜+å†…å®¹ï¼‰ä¹‹é—´æœ‰ç©ºè¡Œ
    lines = text.split('\n')
    formatted_lines = []
    current_section = []  # å½“å‰æ­£åœ¨å¤„ç†çš„ç« èŠ‚
    section_title = None
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„æ ‡é¢˜è¡Œ
        is_header = False
        header_type = None
        if 'ã€é£é™©ç­‰çº§ã€‘' in line:
            is_header = True
            header_type = 'é£é™©ç­‰çº§'
        elif 'ã€é£é™©ç‚¹ã€‘' in line:
            is_header = True
            header_type = 'é£é™©ç‚¹'
        elif 'ã€å–‚å…»å»ºè®®ã€‘' in line:
            is_header = True
            header_type = 'å–‚å…»å»ºè®®'
        
        if is_header:
            # å¦‚æœä¹‹å‰æœ‰ç« èŠ‚ï¼Œå…ˆä¿å­˜å®ƒï¼ˆåœ¨ç« èŠ‚åæ·»åŠ ç©ºè¡Œï¼‰
            if current_section:
                formatted_lines.extend(current_section)
                formatted_lines.append('')  # ç« èŠ‚ä¹‹é—´æ·»åŠ ç©ºè¡Œ
            
            # å¼€å§‹æ–°ç« èŠ‚
            current_section = []
            section_title = header_type
            # ç¡®ä¿æ ‡é¢˜æ ¼å¼æ­£ç¡®
            line = re.sub(r'ã€é£é™©ç­‰çº§ã€‘\s*[:ï¼š]?\s*', 'ã€é£é™©ç­‰çº§ã€‘ï¼š', line)
            line = re.sub(r'ã€é£é™©ç‚¹ã€‘\s*[:ï¼š]?\s*', 'ã€é£é™©ç‚¹ã€‘ï¼š', line)
            line = re.sub(r'ã€å–‚å…»å»ºè®®ã€‘\s*[:ï¼š]?\s*', 'ã€å–‚å…»å»ºè®®ã€‘ï¼š', line)
            current_section.append(line)
        else:
            # å½“å‰è¡Œçš„å†…å®¹å±äºå½“å‰ç« èŠ‚
            if current_section:
                current_section.append(line)
            else:
                # å¦‚æœæ²¡æœ‰å½“å‰ç« èŠ‚ï¼Œç›´æ¥æ·»åŠ ï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰
                formatted_lines.append(line)
    
    # æ·»åŠ æœ€åä¸€ä¸ªç« èŠ‚
    if current_section:
        formatted_lines.extend(current_section)
    
    text = '\n'.join(formatted_lines)
    
    # ç¬¬å…­æ­¥ï¼šæ¸…ç†å¤šä½™çš„ç©ºè¡Œï¼ˆè¶…è¿‡2ä¸ªè¿ç»­æ¢è¡Œå˜ä¸º2ä¸ªï¼‰
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # ç¬¬ä¸ƒæ­¥ï¼šç¡®ä¿æ–‡æœ¬å¼€å¤´å’Œç»“å°¾æ ¼å¼æ­£ç¡®ï¼ˆä½†ä¿ç•™å„ç« èŠ‚ä¹‹é—´çš„ç©ºè¡Œï¼‰
    # åªç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºè¡Œï¼Œä¿ç•™ä¸­é—´çš„ç©ºè¡Œ
    text = text.strip()
    
    return text


_zhipu_client: Optional[ZhipuAiClient] = None

def stream_zhipu_ai_response(question: str, pet_profile: Optional[PetProfile] = None) -> Generator[str, None, None]:
    """æµå¼è°ƒç”¨æ™ºè°± AI æ¥å£ï¼Œå®æ—¶è¿”å›æ–‡æœ¬å—ã€‚
    
    Args:
        question (str): ç”¨æˆ·æå‡ºçš„å® ç‰©é£Ÿå“æˆ–å¥åº·é—®é¢˜ã€‚
        pet_profile: å¯é€‰çš„å® ç‰©æ¡£æ¡ˆä¿¡æ¯ï¼ŒåŒ…å«è¿‡æ•åŸç­‰
    
    Yields:
        str: JSONæ ¼å¼çš„æ•°æ®å—ï¼ŒåŒ…å«contentå­—æ®µã€‚
    """
    start_time = time.time()
    
    # ç”¨äºæ”¶é›†å®Œæ•´å†…å®¹ï¼Œä»¥ä¾¿åœ¨æœ€åè¿›è¡Œæ ¼å¼åŒ–
    full_content_buffer = []
    api_key: Optional[str] = os.getenv("ZHIPU_API_KEY")
    if not api_key:
        error_msg = json.dumps({"error": "æœåŠ¡å™¨æœªé…ç½® AI æœåŠ¡ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚"}, ensure_ascii=False)
        yield f"data: {error_msg}\n\n"
        return

    # ä¼˜åŒ–ï¼šç«‹å³å‘é€"æ€è€ƒä¸­"çŠ¶æ€ï¼Œè®©å‰ç«¯ç«‹å³çŸ¥é“è¯·æ±‚å·²æ”¶åˆ°ï¼ˆä¼˜åŒ–é¦–å­—èŠ‚æ—¶é—´ï¼‰
    # è¿™æ ·å³ä½¿åç»­å¤„ç†æ…¢ï¼Œç”¨æˆ·ä¹Ÿèƒ½ç«‹å³çœ‹åˆ°å“åº”
    yield f"data: {json.dumps({'status': 'thinking'}, ensure_ascii=False)}\n\n"

    global _zhipu_client
    if _zhipu_client is None:
        try:
            _zhipu_client = ZhipuAiClient(api_key=api_key)
        except Exception as exc:
            logger.error("âŒ åˆå§‹åŒ–æ™ºè°± AI å®¢æˆ·ç«¯å¤±è´¥ï¼š%s", exc)
            error_msg = json.dumps({"error": "AI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚"}, ensure_ascii=False)
            yield f"data: {error_msg}\n\n"
            return

    client = _zhipu_client

    # 1. RAG æ£€ç´¢ï¼šæ ¹æ®ç”¨æˆ·é—®é¢˜ä»çŸ¥è¯†åº“ä¸­è·å–ç›¸å…³ä¿¡æ¯ï¼ˆä¼˜åŒ–ï¼šå¿«é€Ÿæ£€ç´¢ï¼Œå‡å°‘å¼€é”€ï¼‰
    rag_context = get_rag_info(question)

    # 2. æ ¹æ®å® ç‰©æ¡£æ¡ˆæ„å»ºåŠ¨æ€ç³»ç»Ÿæç¤ºè¯ï¼ˆä¼˜åŒ–ï¼šç®€åŒ–æç¤ºè¯é•¿åº¦ï¼‰
    system_prompt = build_system_prompt(pet_profile)
    
    # 3. æ„é€ å®Œæ•´çš„ç”¨æˆ· Promptï¼šåŸå§‹é—®é¢˜ + RAG æ£€ç´¢ç»“æœ
    full_user_prompt = question
    if rag_context:
        full_user_prompt += rag_context

    # 4. æ„é€  messages åˆ—è¡¨
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": full_user_prompt},
    ]

    try:
        
        # å¯ç”¨æµå¼ä¼ è¾“
        # ä¼˜åŒ–å‚æ•°ä»¥æå‡é€Ÿåº¦ï¼šé™ä½temperatureã€å‡å°‘max_tokensã€ä¼˜åŒ–æ¨¡å‹å‚æ•°
        response_stream = client.chat.completions.create(
            model=ZHIPU_MODEL_NAME,
            messages=messages,
            stream=True,
            max_tokens=600,  # è®¾ç½®ä¸º600ï¼Œç¡®ä¿ä¸‰ä¸ªéƒ¨åˆ†éƒ½èƒ½å®Œæ•´è¾“å‡º
            temperature=0.1,  # è¿›ä¸€æ­¥é™ä½åˆ°0.1ï¼ŒåŠ å¿«å“åº”é€Ÿåº¦
            top_p=0.8,  # æ·»åŠ top_på‚æ•°ï¼ŒåŠ å¿«é‡‡æ ·é€Ÿåº¦
        )

        first_chunk_time = None
        # æµå¼è¿”å›æ¯ä¸ªæ•°æ®å— - ç›´æ¥è¿­ä»£ï¼Œç«‹å³å‘é€
        for chunk in response_stream:
            # å¤„ç†ä¸åŒç±»å‹çš„chunkï¼ˆdictæˆ–å¯¹è±¡ï¼‰
            if isinstance(chunk, dict):
                choices = chunk.get("choices", [])
            elif hasattr(chunk, "choices"):
                choices = getattr(chunk, "choices", [])
            else:
                # å°è¯•è½¬æ¢ä¸ºdict
                choices = []
                if hasattr(chunk, "__dict__"):
                    chunk_dict = chunk.__dict__
                    choices = chunk_dict.get("choices", [])
            
            if choices and len(choices) > 0:
                choice = choices[0]
                # æå–delta
                if isinstance(choice, dict):
                    delta = choice.get("delta", {})
                elif hasattr(choice, "delta"):
                    delta = getattr(choice, "delta", {})
                else:
                    delta = {}
                
                # æ˜ç¡®å¿½ç•¥æ€è€ƒè¿‡ç¨‹ï¼ˆreasoning_contentï¼‰ï¼Œåªå¤„ç†å®é™…å†…å®¹ï¼ˆcontentï¼‰
                # æ ¹æ®æ™ºè°±AIæ–‡æ¡£ï¼Œæ€è€ƒè¿‡ç¨‹é€šè¿‡ reasoning_content ä¼ é€’ï¼Œå®é™…å†…å®¹é€šè¿‡ content ä¼ é€’
                # ä¸€ä¸ªchunkå¯èƒ½åŒæ—¶åŒ…å« reasoning_content å’Œ contentï¼Œæˆ‘ä»¬åªå¤„ç† content
                if isinstance(delta, dict):
                    # åªæå– contentï¼Œå¿½ç•¥ reasoning_content
                    content = delta.get("content")
                elif hasattr(delta, "content"):
                    content = getattr(delta, "content", None)
                else:
                    content = None
                
                # å¦‚æœè¿™ä¸ªchunkåªæœ‰ reasoning_content è€Œæ²¡æœ‰ contentï¼Œè·³è¿‡
                if not content:
                    continue
                
                if content:
                    # å®æ—¶è¿‡æ»¤æ€è€ƒè¿‡ç¨‹å†…å®¹
                    filtered_content = filter_thinking_content(content)
                    
                    # å¦‚æœè¿‡æ»¤åå†…å®¹ä¸ºç©ºï¼Œè·³è¿‡è¿™ä¸ªchunk
                    if not filtered_content:
                        continue
                    
                    # è®°å½•é¦–å­—èŠ‚æ—¶é—´ï¼ˆä»…ç¬¬ä¸€æ¬¡ï¼‰
                    if first_chunk_time is None:
                        first_chunk_time = time.time()
                        elapsed = first_chunk_time - start_time
                        logger.info(f"âš¡ é¦–å­—èŠ‚æ—¶é—´: {elapsed:.3f}s")
                    
                    # æ”¶é›†å†…å®¹ç”¨äºæœ€ç»ˆæ ¼å¼åŒ–ï¼ˆä½¿ç”¨åŸå§‹å†…å®¹ï¼Œåœ¨æœ€åç»Ÿä¸€è¿‡æ»¤ï¼‰
                    full_content_buffer.append(content)
                    # ç«‹å³å‘é€è¿‡æ»¤åçš„å†…å®¹å—ï¼Œå®ç°çœŸæ­£çš„é€å­—æµå¼ä¼ è¾“
                    data = json.dumps({"content": filtered_content}, ensure_ascii=False)
                    yield f"data: {data}\n\n"

        # æµå¼ä¼ è¾“å®Œæˆåï¼Œè¿›è¡Œæ ¼å¼åŒ–å¤„ç†ï¼ˆå¼‚æ­¥å¤„ç†ï¼Œä¸é˜»å¡æµå¼è¾“å‡ºï¼‰
        if full_content_buffer:
            full_text = ''.join(full_content_buffer)
            
            # åªåœ¨è°ƒè¯•æ¨¡å¼ä¸‹è®°å½•è¯¦ç»†æ—¥å¿—ï¼ˆå‡å°‘æ—¥å¿—å¼€é”€ï¼‰
            if logger.level <= logging.DEBUG:
                logger.debug(f"ğŸ“ åŸå§‹AIå›ç­”ï¼ˆå‰200å­—ç¬¦ï¼‰: {repr(full_text[:200])}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸‰ä¸ªå¿…è¦éƒ¨åˆ†
            has_risk_level = 'ã€é£é™©ç­‰çº§ã€‘' in full_text
            has_risk_point = 'ã€é£é™©ç‚¹ã€‘' in full_text
            has_feeding_advice = 'ã€å–‚å…»å»ºè®®ã€‘' in full_text
            
            if not has_feeding_advice:
                logger.warning("âš ï¸ AIå›ç­”ç¼ºå°‘ã€å–‚å…»å»ºè®®ã€‘éƒ¨åˆ†ï¼Œå¯èƒ½æ˜¯max_tokensä¸è¶³æˆ–è¢«æˆªæ–­")
            
            formatted_text = format_ai_response(full_text)
            
            # å‘é€æ ¼å¼åŒ–åçš„æ–‡æœ¬ï¼ˆå¦‚æœæ ¼å¼æœ‰å˜åŒ–ï¼‰
            if formatted_text != full_text:
                yield f"data: {json.dumps({'formatted': formatted_text}, ensure_ascii=False)}\n\n"

        # å‘é€ç»“æŸæ ‡è®°
        total_time = time.time() - start_time
        logger.info(f"âœ… æµå¼å“åº”å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.3f}s")
        yield f"data: {json.dumps({'done': True}, ensure_ascii=False)}\n\n"

    except Exception as exc:
        logger.error("âŒ è°ƒç”¨æ™ºè°± AI å¤±è´¥ï¼š%s", exc)
        error_msg = json.dumps({"error": "AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"}, ensure_ascii=False)
        yield f"data: {error_msg}\n\n"


@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œç”¨äºå¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "message": "å® ç‰©é£Ÿå“å®‰å…¨ AI é—®ç­”åç«¯æœåŠ¡è¿è¡Œä¸­",
        "version": "1.0.0",
        "endpoints": {
            "ask": "/ask",
            "docs": "/docs"
        }
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy"}

@app.post("/ask")
async def ask_ai(request: AskRequest):
    """å¤„ç†å‰ç«¯å‘èµ·çš„ AI é—®ç­”è¯·æ±‚ï¼ˆæµå¼å“åº”ï¼‰ã€‚"""

    question = request.question.strip()
    if not question:
        raise HTTPException(status_code=400, detail="é—®é¢˜ä¸èƒ½ä¸ºç©ºï¼Œè¯·æä¾›å® ç‰©é£Ÿå“æˆ–å¥åº·ç›¸å…³çš„é—®é¢˜ã€‚")

    # è¿”å›æµå¼å“åº”ï¼Œä½¿ç”¨ Server-Sent Events (SSE)
    # ä¼ é€’å® ç‰©æ¡£æ¡ˆä¿¡æ¯ç»™æµå¼å“åº”å‡½æ•°
    return StreamingResponse(
        stream_zhipu_ai_response(question, request.pet_profile),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # ç¦ç”¨Nginxç¼“å†²
        }
    )


if __name__ == "__main__":
    # å½“ç›´æ¥è¿è¡Œè¯¥æ–‡ä»¶æ—¶ï¼Œå¯åŠ¨ Uvicorn æœåŠ¡å™¨ã€‚
    # host=0.0.0.0 æ–¹ä¾¿åœ¨å±€åŸŸç½‘å†…è®¿é—®ï¼Œç«¯å£é»˜è®¤ 3000ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡ PORT è¦†ç›–ã€‚
    import uvicorn

    port = int(os.getenv("PORT", "3000"))
    logger.info("âœ… AI é—®ç­”æ¥å£å·²å¯åŠ¨ï¼šhttp://localhost:%s", port)
    uvicorn.run("app:app", host="0.0.0.0", port=port, reload=False)

